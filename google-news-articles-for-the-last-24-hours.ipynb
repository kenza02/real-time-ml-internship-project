{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6QU9bvg8bCM",
        "outputId": "e2242123-3be5-42dc-8bc2-93c48c73063d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen, Request\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from langdetect import detect\n",
        "\n",
        "root = \"https://www.google.com/\"\n",
        "\n",
        "# Initial link for the first page\n",
        "link_base = \"https://www.google.com/search?q=tesla&rlz=1C1GCEA_enMA1047MA1047&tbas=0&tbs=qdr:d,sbd:1&tbm=nws&source=lnt&sa=X&ved=2ahUKEwiAmILcsM2AAxWyd6QEHbwdARUQpwV6BAgCEBM&biw=1366&bih=651&dpr=1\"\n",
        "articles_per_page = 10\n",
        "num_pages = 25\n",
        "\n",
        "data = []\n",
        "\n",
        "# Loop through multiple pages\n",
        "for page in range(num_pages):\n",
        "    start_index = page * articles_per_page\n",
        "    link = f\"{link_base}&start={start_index}\"\n",
        "\n",
        "    req = Request(link, headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'})\n",
        "    webpage = urlopen(req).read()\n",
        "\n",
        "    with requests.Session() as c:\n",
        "        soup = BeautifulSoup(webpage, 'html.parser')\n",
        "        articles = soup.find_all('a', class_='WlydOe')\n",
        "\n",
        "    for article in articles:\n",
        "        time_element = article.find('div', class_='OSrXXb')\n",
        "        title_element = article.find('div', class_='n0jPhd')\n",
        "        description_element = article.find('div', class_='GI74Re')\n",
        "\n",
        "        if time_element:\n",
        "            time_string = time_element.span.get_text()\n",
        "            if \"min\" in time_string:\n",
        "                minutes_ago = int(time_string.split()[0])\n",
        "                time = datetime.now() - timedelta(minutes=minutes_ago)\n",
        "            elif \"hour\" in time_string:\n",
        "                hours_ago = int(time_string.split()[0])\n",
        "                time = datetime.now() - timedelta(hours=hours_ago)\n",
        "            else:\n",
        "                time = \"N/A\"\n",
        "        else:\n",
        "            time = \"N/A\"\n",
        "\n",
        "        # Convert time to date and time strings\n",
        "        date_str = time.strftime(\"%Y-%m-%d\")\n",
        "        time_str = time.strftime(\"%H:%M:%S\")\n",
        "\n",
        "        if title_element:\n",
        "            title = title_element.get_text()\n",
        "        else:\n",
        "            title = \"N/A\"\n",
        "\n",
        "        if description_element:\n",
        "            description = description_element.get_text()\n",
        "        else:\n",
        "            description = \"N/A\"\n",
        "\n",
        "        description_language = detect(description)\n",
        "        if description_language == 'en':\n",
        "            data.append({'Date': date_str, 'Time': time_str, 'Title': title, 'Description': description})\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "output_file = 'tesla_articles13.xlsx'\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Data has been scraped and saved to {output_file}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zc4IqR68r1Q",
        "outputId": "b2fd6618-5d89-4b6a-a01d-6d2a4cc05922"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been scraped and saved to tesla_articles13.xlsx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bSaXHk-R8v8D"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}