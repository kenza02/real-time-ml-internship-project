{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wHOdW4vK45gv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e42d111-1993-40a6-92c9-0f91aa894112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: confluent-kafka in /usr/local/lib/python3.10/dist-packages (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install confluent-kafka"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqO0Pgko_3X8",
        "outputId": "3174a513-0940-480f-810e-e6509fe2cbb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "kafka_config = {\n",
        "    'bootstrap.servers': 'pkc-lzvrd.us-west4.gcp.confluent.cloud:9092',\n",
        "    'group.id': 'my-group',\n",
        "    'auto.offset.reset': 'earliest',\n",
        "    'security.protocol': 'SASL_SSL',\n",
        "    'sasl.mechanisms': 'PLAIN',\n",
        "    'sasl.username': '7EEPKRB4LLGJOBSC',\n",
        "    'sasl.password': '0/+d2Vi9vcZOh4g/LJJm4MHs+L6zOt+00LPhiMcTTyjdML5IGP9Wg5Q7aUeWXv2Y'\n",
        "}\n",
        "\n",
        "producer = Producer(kafka_config)\n",
        "\n",
        "\n",
        "from urllib.request import urlopen, Request\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from langdetect import detect\n",
        "\n",
        "root = \"https://www.google.com/\"\n",
        "\n",
        "# Initial link for the first page\n",
        "link_base = \"https://www.google.com/search?q=tesla&rlz=1C1GCEA_enMA1047MA1047&tbas=0&tbs=qdr:d,sbd:1&tbm=nws&source=lnt&sa=X&ved=2ahUKEwiAmILcsM2AAxWyd6QEHbwdARUQpwV6BAgCEBM&biw=1366&bih=651&dpr=1\"\n",
        "articles_per_page = 10\n",
        "num_pages = 25\n",
        "\n",
        "data = []\n",
        "\n",
        "# Loop through multiple pages\n",
        "for page in range(num_pages):\n",
        "    start_index = page * articles_per_page\n",
        "    link = f\"{link_base}&start={start_index}\"\n",
        "\n",
        "    req = Request(link, headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'})\n",
        "    webpage = urlopen(req).read()\n",
        "\n",
        "    with requests.Session() as c:\n",
        "        soup = BeautifulSoup(webpage, 'html.parser')\n",
        "        articles = soup.find_all('a', class_='WlydOe')\n",
        "\n",
        "    for article in articles:\n",
        "        time_element = article.find('div', class_='OSrXXb')\n",
        "        title_element = article.find('div', class_='n0jPhd')\n",
        "        description_element = article.find('div', class_='GI74Re')\n",
        "\n",
        "        if time_element:\n",
        "            time_string = time_element.span.get_text()\n",
        "            if \"min\" in time_string:\n",
        "                minutes_ago = int(time_string.split()[0])\n",
        "                time = datetime.now() - timedelta(minutes=minutes_ago)\n",
        "            elif \"hour\" in time_string:\n",
        "                hours_ago = int(time_string.split()[0])\n",
        "                time = datetime.now() - timedelta(hours=hours_ago)\n",
        "            else:\n",
        "                time = \"N/A\"\n",
        "        else:\n",
        "            time = \"N/A\"\n",
        "\n",
        "        # Convert time to date and time strings\n",
        "        date_str = time.strftime(\"%Y-%m-%d\")\n",
        "        time_str = time.strftime(\"%H:%M:%S\")\n",
        "\n",
        "        if title_element:\n",
        "            title = title_element.get_text()\n",
        "        else:\n",
        "            title = \"N/A\"\n",
        "\n",
        "        if description_element:\n",
        "            description = description_element.get_text()\n",
        "        else:\n",
        "            description = \"N/A\"\n",
        "\n",
        "        description_language = detect(description)\n",
        "        if description_language == 'en':\n",
        "            data.append({'Date': date_str, 'Time': time_str, 'Title': title, 'Description': description})\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "output_file = 'tesla_articles13.xlsx'\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Data has been scraped and saved to {output_file}.\")\n",
        "# Convert the data to a string or a specific format (e.g., JSON)\n",
        "data_string = df.to_json()  # Convert the DataFrame to a JSON string\n",
        "\n",
        "# Publish the data to a Kafka topic\n",
        "producer.produce('Tesla1', key='7EEPKRB4LLGJOBSC', value=data_string)\n",
        "\n",
        "# Wait for any outstanding messages to be delivered and delivery reports received\n",
        "producer.flush()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbOpez0z_dtg",
        "outputId": "4efe5f59-bae6-40a5-9919-715ac3db845f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been scraped and saved to tesla_articles13.xlsx.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Consumer, KafkaError\n",
        "\n",
        "# Kafka consumer configuration\n",
        "kafka_config = {\n",
        "    'bootstrap.servers': 'pkc-lzvrd.us-west4.gcp.confluent.cloud:9092',\n",
        "    'group.id': 'my-group',\n",
        "    'auto.offset.reset': 'earliest',\n",
        "    'security.protocol': 'SASL_SSL',\n",
        "    'sasl.mechanisms': 'PLAIN',\n",
        "    'sasl.username': '7EEPKRB4LLGJOBSC',\n",
        "    'sasl.password': '0/+d2Vi9vcZOh4g/LJJm4MHs+L6zOt+00LPhiMcTTyjdML5IGP9Wg5Q7aUeWXv2Y'\n",
        "}\n",
        "\n",
        "# Create a Kafka consumer instance\n",
        "consumer = Consumer(kafka_config)\n",
        "\n",
        "# Subscribe to the Kafka topic where data is being published\n",
        "consumer.subscribe(['Tesla1'])\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        msg = consumer.poll(1.0)\n",
        "\n",
        "        if msg is None:\n",
        "            continue\n",
        "        if msg.error():\n",
        "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
        "                print('Reached end of partition')\n",
        "            else:\n",
        "                print('Error: {}'.format(msg.error()))\n",
        "        else:\n",
        "            # Print the received message's key and value\n",
        "            print('Received message key: {}, value: {}'.format(msg.key(), msg.value()))\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "finally:\n",
        "    consumer.close()\n"
      ],
      "metadata": {
        "id": "XfDZ4aHvAZ79"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}